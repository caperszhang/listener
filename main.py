import streamlit as st
from langchain.memory import ConversationBufferMemory

from utils import get_chat_response



st.title("ğŸ’¬ æ ‘æ´ï¼Œé˜…åå³ç„š")

openai_api_key = "sk-a8acecc0a0aa4bc5a0ff27c8fe8f42c8"

if "memory" not in st.session_state:
    st.session_state["memory"] = ConversationBufferMemory(return_messages=True)
    st.session_state["messages"] = [{"role": "ai",
                                     "content": "æˆ‘æ˜¯ä½ çš„æ ‘æ´ï¼Œä½ å¯ä»¥åœ¨è¿™é‡Œå€¾è¯‰ä½ çš„å¿ƒå£°ï¼Œæˆ‘ä¼šå€¾å¬ä½ çš„æ•…äº‹ã€‚"}]

for message in st.session_state["messages"]:
    st.chat_message(message["role"]).write(message["content"])

prompt = st.chat_input(placeholder="è¯·è¾“å…¥ä½ çš„å¿ƒå£°")
if prompt:
    if not openai_api_key:
        st.info("è¯·è¾“å…¥ä½ çš„OpenAI API Key")
        st.stop()
    st.session_state["messages"].append({"role": "human", "content": prompt})
    st.chat_message("human").write(prompt)

    with st.spinner("æ ‘æ´æ²‰åŸç‰‡åˆ»..."):
        response = get_chat_response(prompt, st.session_state["memory"],
                                     openai_api_key)
    msg = {"role": "ai", "content": response}
    st.session_state["messages"].append(msg)
    st.chat_message("ai").write(response)